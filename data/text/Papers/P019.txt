Acquiring the Ability to Recommend Interventions for Tuberculosis
Treatment Through the Utilization of Digital Adherence Information
Abstract
Digital Adherence Technologies (DATs) are becoming progressively favored as a means of confirming patients’
adherence to various medications. This paper examines the information gathered from a city that utilizes 99DOTS,
a telephone-based DAT implemented for tuberculosis (TB) treatment in India, where approximately 3 million
individuals are diagnosed with the disease annually. The dataset encompasses approximately 17,000 patients
and 2.1 million dosage records. This research establishes the basis for deriving insights from this real-world
data, encompassing a methodology to circumvent the influence of unrecorded interventions in the training
data employed for machine learning. Subsequently, a deep learning model is developed, its interpretability is
illustrated, and it is demonstrated how it can be modified and trained under diverse clinical conditions to more
effectively target and enhance patient treatment. In the context of real-time risk prediction, the model could be
employed to proactively intervene with 21% more patients and prevent 76% more missed doses compared to
the current heuristic benchmarks. Regarding outcome prediction, the model exhibits 40% improvement over
baseline approaches, enabling cities to allocate more resources to clinics with a higher proportion of patients
susceptible to treatment failure. Lastly, a case study is presented that illustrates how the model can be trained in an
end-to-end, decision-focused learning framework to realize a 15% enhancement in solution quality in a sample
decision problem encountered by healthcare professionals.
1 Introduction
The World Health Organization (WHO) has identified tuberculosis (TB) as one of the leading ten causes of mortality globally, despite
it being a curable and preventable disease in the majority of instances. The widespread occurrence of TB is partially attributable
to inadequate adherence to medication, which leads to an elevated probability of mortality, reinfection, and the development of
drug-resistant strains of TB. To address the issue of non-adherence, the WHO advocates for directly observed treatment (DOT),
wherein a healthcare professional directly observes and validates a patient’s daily intake of the necessary medication. Nevertheless,
the necessity for patients to commute to the DOT facility imposes a financial strain and potentially introduces social stigma because
of the public apprehension surrounding the disease. These obstacles make it challenging to eradicate TB, as they contribute to
patients being lost to follow-up. Consequently, digital adherence technologies (DATs), which offer patients adaptable methods to
demonstrate adherence, have experienced a surge in popularity on a global scale.
DATs empower patients to be "observed" consuming their medication electronically through various means, such as two-way
text messaging, video recording, electronic pill containers, or toll-free phone calls. Healthcare professionals can subsequently
monitor patient adherence in real-time using a dashboard. Besides enhancing patient adaptability and confidentiality, the dashboard
empowers healthcare personnel to categorize patients and allocate their constrained resources towards those at the highest risk.
Initial research indicates that DATs have the potential to enhance adherence in various disease contexts, thereby stimulating their
utilization and assessment for the management of TB adherence. The WHO has even issued a manual for the effective incorporation
of this technology in TB patient care.
In this paper, the focus is on investigating how the extensive longitudinal data generated by DATs can be utilized to assist health
workers in better triaging TB patients and providing interventions to enhance the overall adherence of their patient group. The data
under analysis originates from Mumbai, India, and is the result of a collaboration with the City TB Office of Mumbai. They have
put into practice a DAT that enables patients to verify their adherence by making daily toll-free calls. The DAT system was set
up with technical assistance from the healthcare technology company Everwell and is recognized as 99DOTS. Everwell provides
support for the implementation of 99DOTS across India, where there were an estimated 2.7 million cases of TB in 2017. In Mumbai,
patients registered in 99DOTS currently receive interventions based on the following broad guidelines. If they have not taken their
medication by the afternoon, they (and their health worker) get a text message reminder. If the patient still does not take their
medication after some time, the worker will call the patient directly. Lastly, if a patient does not respond to these interventions after
a certain number of days, they may be personally visited by a health worker. It is important to note that a significant number of these
patients reside in communities with limited resources, where each health worker is responsible for managing dozens to hundreds
of patients, far exceeding their capacity for daily visits. Therefore, models that can pinpoint patients at risk of missing doses and
prioritize interventions by health workers are of the utmost importance.
At first, the challenge of determining whom to target for an intervention seems to be a straightforward supervised machine learning
task. Provided with information regarding a patient’s medication adherence as indicated by their calls to the 99DOTS system, it is
possible to train a machine learning model to forecast whether they will miss medication doses in the future. Nevertheless, such a
model disregards the simultaneous interventions carried out by health workers during the data collection period and may result in
erroneous prioritization choices, even when it exhibits high accuracy. As an illustration, it might be observed that missed doses are
succeeded by a phase of medication adherence. This observation does not imply that individuals who miss doses are more inclined
to take medication, but rather suggests that an intervention by a health worker likely occurred, after which the patient resumed their
medication.
Therefore, to prescribe interventions, it’s necessary to separate the impact of manual interventions from other underlying elements
that contribute to missed doses. However, because this data was gathered through a wide-ranging implementation involving actual
patients, it incorporates the impacts of interventions executed by healthcare personnel. An added difficulty is that healthcare workers
seldom document their interventions within the 99DOTS system, making it hard to gauge their consequences. Although there is a
substantial body of research on assessing heterogeneous treatment effects, conventional methods consistently necessitate awareness
of which patients underwent an intervention. It should be noted that such omissions will be prevalent as nations enthusiastically
implement DAT systems with the aim of aiding low-income areas. To facilitate the provision of enhanced care, it is imperative that
we can glean insights from this complex yet abundant data.
Hence, a general strategy is introduced for acquiring knowledge from adherence data with unrecorded interventions, grounded in
domain expertise regarding the intervention heuristics used by healthcare workers. A proxy is created for interventions evident in
the historical 99DOTS data, and a model is devised to aid in prioritizing intervention targets for healthcare workers across various
clinical scenarios.
2 Methodology
The TB treatment system functions under severe resource constraints; for instance, a single health worker might be in charge of
over 100 patients. Therefore, it is essential that workers can precisely evaluate patient risk and prioritize interventions appropriately.
Although machine learning can be employed to carry out such risk assessment with encouraging precision, it necessitates careful
consideration of how intervention resources were distributed in the current data.
A significant obstacle arises from the fact that users of the 99DOTS platform typically do not document interventions. Health
workers might send texts, make calls, or conduct personal visits to patients in an effort to boost adherence, but these interventions are
not systematically recorded in the data. Although far from perfect, these gaps are unavoidable as countries with varying reporting
standards adopt DATs for TB treatment. Considering the wealth of data produced by DATs and their potential to affect human
lives, the importance of learning lessons in this demanding setting where unobserved interventions take place is emphasized. This
challenge is subsequently addressed by developing a screening procedure that recognizes patients who were probable candidates for
specific interventions.
The aim is to utilize the accessible data to create an approximation for when an intervention likely took place, enabling the training
of models on data points unaffected by interventions. The initial step involves differentiating between various categories of health
worker interventions. Specifically, a house visit is regarded as a "resource-limited" intervention, given that workers are unable to visit
all their patients promptly. Typically, this represents a last resort for health workers when patients are unresponsive to alternative
methods. On the other hand, calls and texts are viewed as "non-resource-limited" interventions, as they could feasibly be conducted
on a large patient population at minimal expense.
To develop the proxy, a search was conducted for health worker guidelines concerning house visits. The 2005 guide by India’s
Revised National Tuberculosis Control Program (RNTCP) mandated that workers perform a house visit after a single missed dose.
However, more recent guidelines are considerably more ambiguous on this matter. Both the latest guide by the WHO and the
RNTCP leave house visits to the health worker’s discretion. Nevertheless, through discussions in Mumbai, it was discerned that
health workers give precedence to non-adherent patients for resource-limited interventions like house visits. Consequently, the proxy
was formulated based on the adherence dashboard accessible to health workers.
The 99DOTS dashboard provides a daily "Attention Required" status for each patient. Initially, if a patient has a record in the Patient
Log, signifying that a provider made a note about the patient within the preceding 7 days, their status is automatically adjusted to
"MEDIUM" attention. However, this guideline impacts fewer than 1% of the labels. The remaining 99% of labels are determined as
follows: if a patient misses 0 or 1 doses in the past 7 days, their attention level is changed to "MEDIUM." If they miss 4 or more, it
is changed to "HIGH." Patients with 2-3 missed doses maintain their attention level from the day before. As a conservative proxy, it
was assumed that only "HIGH" attention patients were candidates for resource-limited interventions, considering that the attention
level serves as a health worker’s primary overview of recent patient adherence. This "Attention Required" system for screening
resource-limited interventions is applicable to any daily adherence context; one only needs to ascertain the threshold for a change to
HIGH attention.
2
Employing this screening system, sequences of days can be identified during which a patient was a candidate for a resource-limited
intervention, and subsequently, the use of signal from those days in the training task can be avoided.
3 Experiments
The objective was to create a model that mirrors the daily routine of a health worker, which involves analyzing their patients’ recent
call records to gauge adherence risk and subsequently planning various types of interventions. Enhanced prediction capabilities
enable workers to engage with a greater number of patients proactively, prior to their missing crucial doses.
The process began with the entire group of 16,975 patients and proceeded to create training samples from each patient in the
following manner. All consecutive sequences of 14 days of call data were considered, ensuring that the initial 7 days of each
sequence did not overlap. The first 7 days of each patient’s treatment, as well as the final day, were omitted to prevent any bias that
might arise from interactions with health workers during the initiation or conclusion of treatment. Two filtering steps were then
implemented. Initially, samples were excluded where the patient had in excess of 2 doses manually recorded by a provider during the
input sequence, as these patients likely had contact with their provider outside of the 99DOTS system. Secondly, samples in which
the patient did not miss any doses in the input sequence were removed. Although these samples constituted the majority of the data,
they included almost no positive (HIGH risk) labels, which distorted the training process. Moreover, positive predictions for patients
who missed 0 doses are improbable to be beneficial; no resource-limited intervention can be implemented so extensively that patients
with flawless recent adherence are targeted. The aforementioned steps yielded 16,015 samples, of which 2,437 were positive.
Each sample comprised a time-series of call data along with static characteristics. The time series encompassed two sequences of 7
in length for every sample. The initial sequence was a binary representation of call data, where 1 signified a call or manual dose
and 0 indicated a miss. The subsequent sequence represented a cumulative count of all doses missed up to that specific day, taking
into account the patient’s entire history within the program. The static features incorporated four demographic attributes from the
Patient Table: weight-band, age-band, gender, and treatment center ID. Supplementary features were derived from the patient Call
Logs and captured a patient’s behavior beyond mere adherence. For instance, did the patient call at a consistent time each morning
or at irregular intervals throughout the day? This was captured by calculating the mean and variance of the call minute and hour.
Additional features encompassed the number of calls, number of manual doses, and the mean, maximum, and variance of calls per
day, in addition to days per call. Analogous features were also incorporated, which exclusively utilized unique calls per day (i.e.,
calls to distinct phone numbers) or disregarded manual doses. This procedure resulted in 29 descriptive features.
Initially, standard models were tested that utilize solely the static features: linear regression, a random forest (with 100 trees and a
maximum depth of 5), and a support vector machine. The random forest exhibited the best performance, so the others are omitted for
the sake of clarity. To make use of the time series data, a deep network was also constructed, designated as LEAP (Lstm rEal-time
Adherence Predictor), which accepts both the time series and static features as input. LEAP comprises two input layers: 1) an LSTM
with 64 hidden units for the time series input, and 2) a dense layer with 100 units for the static feature input. The outputs of these
two layers were concatenated and fed forward into another dense layer with 16 units, followed by a single sigmoid activation unit. A
batch size of 128 was employed, and training was conducted for 20 epochs.
To assess the models, all data was randomized, and 25% was set aside as the test set. A 4-fold grid search was employed to ascertain
the optimal model parameters. To address class imbalance, SMOTE was utilized to oversample the training set, implemented using
the Python library imblearn. Features were also normalized as percentiles using SKLearn, which was empirically found to be
effective. The benchmark for comparison was the method employed by the current 99DOTS platform to evaluate risk, namely, doses
missed by the patient in the preceding week (lw-Misses).
4 Results
The models were compared against the baseline. The random forest slightly surpasses the baseline, and LEAP distinctly outperforms
both. Nevertheless, to gauge the efficacy of the methods relative to the baseline, a comparison is made regarding how each method
could be applied to strategize house-visit interventions. Given that this constitutes a highly constrained resource, the most stringent
baseline threshold was established to contemplate patients for this intervention, specifically, 3 missed calls. Maintaining the FPR of
this baseline method, it is demonstrated how many more patients in the test set would be reached weekly by the proposed method
(owing to its enhanced TPR), alongside the enhancement in the quantity of missed doses detected. To ascertain the number of missed
doses caught, only missed doses that transpired before the patient’s transition to HIGH risk are counted. The model identifies 21.6%
more patients and captures 76.5% more missed doses, signifying substantially more accurate targeting than the baseline.
It is shown that the model also surpasses the baseline as both the true positive rate (TPR) and FPR escalate, underscoring the model’s
superior discriminatory capability. This proves advantageous for interventions not constrained by resources, like calls or texts. It
is important to remember that the screening procedure is not pertinent to this category of intervention; therefore, the predictions
can solely advocate for supplementary interventions. It is crucial that additional interventions are meticulously aimed, as repeated
engagement with a specific patient diminishes the effectiveness of each subsequent interaction over time. This emphasizes the
significance of the enhanced precision provided by the model, as merely inundating the entire population with calls and texts is
probable to be ineffective.
3
The model has the capability to prevent a greater number of missed doses compared to existing approaches. Nonetheless, these
advancements cannot be realized unless health workers on the ground administer interventions in accordance with the predictions.
Consequently, interpretability emerges as a crucial determinant of the model’s utility, as health workers must comprehend the
rationale behind the model’s predictions to trust it and incorporate its logic with their own professional expertise.
The superior predictive performance was attained with LEAP, a black-box network, as opposed to an inherently interpretable model
such as linear regression. As a result, it is demonstrated how a visualization instrument can assist users in extracting insights
regarding the model’s reasoning. The SHapley Additive exPlanations (SHAP) python library was employed, which produces
visualizations to elucidate machine learning models. It is illustrated how static features affect the model’s prediction, where red
features drive predictions toward 1 (HIGH) and blue toward 0 (MEDIUM). It is important to recall that features are scaled as
percentiles. In the blue region, it is observed that this patient makes an above-average number of calls each week, pushing the
prediction toward 0. Conversely, in the red region, it is noted that this patient has a very low average but a high variability in time
between calls. These features capture that this patient missed two days of calls, then made three calls on one day in an attempt to
"back log" their previous missed calls. The model learned that this is a high-risk behavior.
Four distinct samples are presented as input to the LSTM layer of the model. On the left, the binary input sequence is depicted as
colored pixels, where black represents a call and yellow signifies a missed call. On the right, SHAP values corresponding to each
day of adherence data are displayed, and grey denotes the commencement of the call sequence. It is observed that the model has
discerned that calls made later in the week carry more weight than those made earlier. In Sample 1, the bottom two pixels (the most
recent calls) have blue SHAP values, while the other pixels have SHAP values close to 0. In Sample 3, a single missed call at the
beginning of the week, combined with a call made at the end of the week, result in essentially canceling SHAP values. Sample 4
also has one missed call, but on the last day of the week, resulting in a net positive SHAP value.
This visualization method offers intuitive insights into the principles acquired by the model. In a real-world application, healthcare
professionals could produce these visualizations for any given sample on-the-fly to support their decision-making procedure.
5 Conclusion
A framework is introduced for acquiring the ability to generate intervention recommendations from data produced by DAT systems
used in TB care. A comprehensive strategy is formulated for learning from medical adherence data that includes unrecorded
interventions, and this strategy is utilized to construct a model for forecasting risk in various contexts. In the real-time adherence
scenario, it is demonstrated that the model would empower health workers to more precisely direct interventions to high-risk patients
at an earlier stage, identifying 21% more patients and preventing 76% more missed doses than the existing heuristic benchmark.
Subsequently, the model is trained for outcome prediction, illustrating how adherence data can more accurately detect patients
at risk of unfavorable treatment outcomes. Insights are then derived that could assist health workers in accurately identifying
LCFO patients using a straightforward rule after a mere 7 days of treatment. Finally, it is demonstrated that adapting the LEAP
model for a particular intervention through decision-focused learning can enhance performance by an additional 15%. The learning
methodologies presented here are versatile and could be applied to analyze data generated by DATs for any medication schedule.
Given the increasing adoption of DAT systems for TB, HIV , diabetes, heart disease, and other medications, this work aims to
establish the groundwork for enhanced patient outcomes in healthcare settings worldwide.
6 Outcome Prediction
The subsequent phase involves an investigation into how adherence data can be employed to forecast the ultimate treatment outcome.
Conventional studies on TB treatment typically model outcomes solely in relation to patient covariates, such as demographic
characteristics. By utilizing daily real-time adherence data furnished by DATs, an exploration is conducted into how employing
the initial k days of a patient’s adherence facilitates more precise, individualized outcome predictions. It is important to note
that intervention effects are still discernible in this configuration. Nevertheless, the screening procedure will not be applicable,
as predictions are made over a span of several months, during which practically all patients would have had recurring in-person
interactions with healthcare providers.
The prediction task is formalized in the following manner: given the first k days of adherence data, predict the final binary treatment
outcome. "Cured" and "Treatment Complete" were regarded as favorable outcomes, while "Died," "Lost to follow-up," and
"Treatment Failure" were considered unfavorable. Solely patients who were assigned an outcome from these classifications are
incorporated. Furthermore, given that patients with the outcome "Died" or "Lost to follow-up" exit the program prior to the full 6
months of treatment, those who were present for less than k + 1 days were excluded. Lastly, patients who had in excess of half their
first k days marked as manual doses were omitted. This was inclined to enhance prediction performance, which is conjectured to be
associated with the observation that practices for reporting manual doses varied by health center, rendering the "significance" of a
manual dose ambiguous across samples with respect to outcome. The final dataset comprised 4167 samples, with 433 unfavorable
cases.
Through discussions in Mumbai, it was learned that health workers often build a sense of a patient’s risk of an unfavorable outcome
within their first month of treatment. To model this process, k=35 was set for the prediction task, capturing the first month of each
patient’s adherence after enrollment in 99DOTS. (Note that this is not a general rule for health workers, but simply served as a
4
motivation for the choice of k in this task.) Both the static features and the sequence inputs were the same as calculated for the
weekly prediction task, but now taken over the initial 35 days. Two versions of the health worker baseline were included: missed
doses in the last week (lw-Misses) and total missed doses in 35 days (t-Misses).
The same models, grid search design, training process, and evaluation procedure as before were used. For the Random Forest, 150
trees were used with no maximum depth. For LEAP, 64 hidden units were used for the LSTM input layer, 48 units for the dense
layer input, and 4 units in the penultimate dense layer.
Even the rudimentary baseline of tallying the calls made in the preceding 7 days before the 35-day threshold is somewhat predictive
of the outcome, implying that the daily data provided by DATs is valuable in assessing which patients will fail TB treatment. The
ML models exhibit even greater predictive capability, with LEAP leading in performance, closely followed by the random forest.
It is emphasized how LEAP’s predictive ability could aid officials in minimizing the expenses required to meet medical outcome
targets for their city. For instance, suppose Mumbai initiates a new program to capture 80% of unfavorable outcomes (true positives)
by recruiting additional health staff. Across the 17,000 patients in Mumbai, where 10% have unsuccessful outcomes as in the test
set, an 80% capture rate necessitates rescuing 1360 patients. Employing either baseline, attaining the 80% TPR necessitates an FPR
of 70%, which translates to hiring extra staff to support 10710 total patients in this hypothetical scenario. However, utilizing LEAP
only results in an FPR of 42%, corresponding to 6426 total patients. It is important to remember that in Mumbai, the typical health
worker attends to approximately 25 patients. With a yearly starting salary of |216,864, the model would result in |37M in saved costs
annually.
7 Detecting Low-Call Favorable Outcome Patients
An additional significant hurdle within the 99DOTS system is that certain patients consistently take their doses as directed but opt not
to call. Consequently, according to the dashboard, they appear to be missing doses and would be categorized as HIGH risk by both
99DOTS and LEAP. However, in actuality, they should be classified as MEDIUM risk. In fact, almost 15% of patients who had an
outcome assigned as in section 3 called on fewer than 25% of the days during their treatment, yet experienced a favorable outcome.
These patients are referred to as low-call favorable outcome (LCFO). The aim is to learn to recognize these LCFO patients to avoid
incorrectly classifying them as HIGH risk, despite their lack of calls. Additionally, there is a desire to identify these patients early in
their treatment so they can be reassigned to an adherence monitoring method that is more appropriate for them.
This is framed as a binary prediction task as follows: given the first k days of adherence data, predict whether the patient will both
call on less than 25% of days from day k + 1 onward and have a favorable outcome. Only patients who were assigned an outcome as
in Section 3 and who had at least k + 7 days of adherence data were included. To detect LCFO status as early as possible, k was set
to 7. Thus, the final dataset contained 7265 patients, of which 1124 were positive. Note that this population was larger than that of
the outcome prediction task because 1) patients were required to be in the program for less time and 2) patients were not removed
for having too many manual doses since this was found to correlate with being LCFO.
Both the static features and the sequence inputs were the same as calculated for the outcome prediction task, but this time taken over
the initial 7 days. The health worker baseline of missed doses in the last week (lw-Misses) was included, along with a random forest
trained only on demographic or "0-day" data (RF 0-day), a simple baseline that counts the number of manual doses in the last week
(lw-Manual), a random forest trained on all non-sequence features over the initial 7 days (RF), and LEAP trained on all features and
sequences.
The same models, grid search design, training process, and evaluation procedure as the previous two formulations were used. For RF
0-day, 300 trees were used with a maximum depth of 10. For RF, 200 trees were used with a maximum depth of 10. For LEAP, 200
hidden units were used for the LSTM input layer, 1000 units for the dense layer input, and 16 units in the penultimate dense layer.
Interestingly, for this task, the lw-Misses baseline has almost no predictive power. Conversely, the performance of the lw-Manual
heuristic is notable, which simply counts the number of manual doses marked in the first 7 days for each patient. This simple
heuristic has almost equivalent predictive power to the machine learning models. This is a valuable insight for health workers,
suggesting that if the worker is already manually marking doses for a patient early in their treatment, the patient is likely to continue
to be disengaged with the system in the long term and should be considered for different adherence technology. The RF 0-day model
has decent predictive power, though closer inspection reveals that most of this power is encoded in the treatment center ID – that is,
LCFO patients tend to be concentrated at certain treatment centers. This insight merits closer inspection by supervisors about why
patients in certain regions tend to be disengaged with 99DOTS but still consuming pills. The RF and LEAP models both perform
slightly better than the lw-Manual baseline but similarly to each other, suggesting that the adherence sequence structure does not
encode additional information for this prediction task. These insights could improve processes by 1) helping to identify hotspot
regions of LCFO patients, after which supervisors might investigate the underlying reason and adjust treatment accordingly at those
centers and 2) the lw-Manual baseline, after only 7 days of dosage data, could give health workers a simple rule for identifying
LCFO patients that should switch to different adherence technology.
5
8 Decision Focused Learning
This section delves into a case study illustrating how the LEAP model can be specialized to furnish decision support for a specific
intervention. The end-to-end differentiability of the model is utilized to supplant the earlier loss function (binary cross-entropy)
with a performance metric customized to the objective and limitations of a particular decision problem. To realize this end-to-end
training, recent developments in decision-focused learning are employed, which incorporates an optimization model within the
machine learning training loop.
The focus is on a particular optimization problem that simulates the allocation of health workers to intervene with patients who are
at risk in the near future. This proactive intervention is facilitated by the real-time risk predictions and exemplifies how the system
can empower preemptive, focused action by providers. Nonetheless, it is underscored that the system can be readily adapted to
accommodate other intervention problems. Such adaptability is one of the advantages of the technical approach, which permits the
ML model to automatically adjust to the problem delineated by a domain expert.
The optimization problem models a health worker who orchestrates a sequence of interventions throughout a week. The health
worker is accountable for a patient population across various locations and may visit one location daily. Location identifiers are
employed at the TB Unit level, as this is the most detailed identifier shared by the majority of patients in the dataset. Visiting a
location enables the health worker to intervene with any of the patients at that location. The optimization problem involves choosing
a set of locations to visit that maximizes the number of patients who receive an intervention on or before the first day they would
have missed a dose. This quantity is referred to as the number of successful interventions, which is selected as the objective for two
rationales. Firstly, it gauges the degree to which the health worker can proactively engage with patients before adherence declines.
Secondly, this objective exclusively counts patients who commence the week at MEDIUM attention and receive an intervention
before they could have transitioned to HIGH, aligning with the earlier discussion on circumventing unobserved interventions in the
data. This extends the earlier intervention proxy to manage day-by-day rewards.
The optimization problem can be formalized as a linear program. There is a set of locations i= 1, . . . , L and patients j= 1, . . . , N ,
where patient jhas location ℓj. Over the days of the week t= 1, . . . , 7, the objective coefficient cjtis 1 if an intervention on day t
with patient jis successful and 0 otherwise. The decision variable is xit, which takes the value 1 if the health worker visits location
ion day tand 0 otherwise. With this notation, the final LP is as follows:
max7X
t=1NX
j=1cjtxℓj,t
subject to:
7X
t=1xit≤1∀i, x it∈ {0,1}.
Here, the second constraint prevents the objective from double-counting multiple visits to a location. It is noted that the feasible
region of the LP can be demonstrated to be equivalent to a bipartite matching polytope, implying that the optimal solution is always
integral.
The machine learning task involves predicting the values of cjt, which are unknown at the start of the week. Three models are
compared. Firstly, the lw-Misses baseline is extended to this setting by thresholding the number of doses patient j missed in the last
week, setting cjt= 0 for all t if this value falls below the threshold τandcjt= 1 otherwise. τ= 1 was used as it performed best.
Secondly, the LEAP system was trained directly on the true cjtas a binary prediction task using cross-entropy loss. Thirdly, LEAP
was trained to predict cjtusing performance on the above optimization problem as the loss function (training via the differentiable
surrogate). This model is referred to as LEAP-Decision.
Instances of the decision problem were created by randomly dividing patients into groups of 100, simulating a health worker under
severe resource limitations (as they would benefit most from such a system). All patients were included, even those with no missed
doses in the last week, since the overall resource allocation problem over locations must still account for them.
LEAP and LEAP-Decision both outperform lw-Misses, as anticipated. LEAP-Decision enhances the number of successful
interventions by roughly 15% compared to LEAP, showcasing the merit of customizing the learned model to a given planning
problem. LEAP-Decision actually has a lower AUC than either LEAP or lw-Misses, suggesting that conventional measures of
machine learning accuracy are not an ideal proxy for utility in decision-making. To investigate what specifically distinguishes the
predictions made by LEAP-Decision, scatter plots of the predicted utility at each location according to LEAP and LEAP-Decision
versus the true values are presented. Visually, LEAP-Decision appears better able to distinguish the high-utility outliers which are
most important to making good decisions. Quantitatively, LEAP-Decision’s predictions have worse correlation with the ground truth
overall (0.463, versus 0.519 for LEAP), but better correlation on locations where the true utility is strictly more than 1 (0.504 versus
0.409). Hence, decision-focused training incentivizes the model to focus on making accurate predictions specifically for locations
that are likely to be good candidates for an intervention. This demonstrates the benefit of the flexible machine learning modeling
approach, which can use custom-defined loss functions to automatically adapt to particular decision problems.
6
Table 1: Data Summary. *Doses per patient was calculated only on patients enrolled at least 6 months before Sept 2018.
Metric Count
Total doses recorded 2,169,976
–By patient call 1,459,908
–Manual (entered by health worker) 710,068
Registered phones 38,000
Patients 16,975
Health centers 252
Doses recorded per patient*
–Quartiles 57/149/188
–Min/Mean/Max 1/136/1409
Active patients per center per month
–Quartiles 7/18/35
–Min/Mean/Max 1/25/226
Table 2: LEAP vs. Baseline - Missed Doses Caught
Method True Positives Doses Caught
Baseline 204 204
LEAP 248 360
Improvement 21.6% 76.5%
Table 3: LEAP vs. Baseline: Additional Interventions
TPR Baseline FPR LEAP FPR Improvement
75% 50% 35% 30%
80% 63% 41% 35%
90% 82% 61% 26%
7